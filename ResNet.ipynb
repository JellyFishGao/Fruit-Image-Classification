{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269514ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Ignore annoying red warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get computing hardware\n",
    "# Use GPU if available, otherwise use CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c9e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Training set image preprocessing: scaling and cropping, image augmentation, conversion to Tensor, normalization\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "# Test set image preprocessing - RCTN: scaling, cropping, conversion to Tensor, normalization\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c987f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directory path\n",
    "dataset_dir = 'fruit30_split'  # Dataset directory path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b82f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set path fruit30_split\\train\n",
      "Test set path fruit30_split\\val\n",
      "Number of training images 4375\n",
      "Number of categories 30\n",
      "Category names ['Apple_Green', 'Apple_Red', 'Banana', 'Bayberry', 'Bitter_Melon', 'Cantaloupe', 'Carrot', 'Cherry', 'Coconut', 'Cucumber', 'Durian', 'Grape_Red', 'Grape_Tomato', 'Grape_White', 'Grapefruit', 'Kiwi', 'Lemon', 'Litchi', 'Longan', 'Mandrian_Orange', 'Mango', 'Mangosteen', 'Orange', 'Pear', 'Pineapple', 'Pitaya', 'Pomegranate', 'Strawberry', 'Tomato', 'Watermelon']\n",
      "Number of test images 1078\n",
      "Number of categories 30\n",
      "Category names ['Apple_Green', 'Apple_Red', 'Banana', 'Bayberry', 'Bitter_Melon', 'Cantaloupe', 'Carrot', 'Cherry', 'Coconut', 'Cucumber', 'Durian', 'Grape_Red', 'Grape_Tomato', 'Grape_White', 'Grapefruit', 'Kiwi', 'Lemon', 'Litchi', 'Longan', 'Mandrian_Orange', 'Mango', 'Mangosteen', 'Orange', 'Pear', 'Pineapple', 'Pitaya', 'Pomegranate', 'Strawberry', 'Tomato', 'Watermelon']\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(dataset_dir, 'train')\n",
    "test_path = os.path.join(dataset_dir, 'val')\n",
    "print('Training set path', train_path)\n",
    "print('Test set path', test_path)\n",
    "\n",
    "from torchvision import datasets\n",
    "# Load the training set\n",
    "train_dataset = datasets.ImageFolder(train_path, train_transform)\n",
    "# Load the test set\n",
    "test_dataset = datasets.ImageFolder(test_path, test_transform)\n",
    "\n",
    "print('Number of training images', len(train_dataset))\n",
    "print('Number of categories', len(train_dataset.classes))\n",
    "print('Category names', train_dataset.classes)\n",
    "print('Number of test images', len(test_dataset))\n",
    "print('Number of categories', len(test_dataset.classes))\n",
    "print('Category names', test_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f12e9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category names\n",
    "class_names = train_dataset.classes\n",
    "n_class = len(class_names)\n",
    "# Mapping: category to index\n",
    "train_dataset.class_to_idx\n",
    "# Mapping: index to category\n",
    "idx_to_labels = {y: x for x, y in train_dataset.class_to_idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a3c684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Apple_Green',\n",
       " 1: 'Apple_Red',\n",
       " 2: 'Banana',\n",
       " 3: 'Bayberry',\n",
       " 4: 'Bitter_Melon',\n",
       " 5: 'Cantaloupe',\n",
       " 6: 'Carrot',\n",
       " 7: 'Cherry',\n",
       " 8: 'Coconut',\n",
       " 9: 'Cucumber',\n",
       " 10: 'Durian',\n",
       " 11: 'Grape_Red',\n",
       " 12: 'Grape_Tomato',\n",
       " 13: 'Grape_White',\n",
       " 14: 'Grapefruit',\n",
       " 15: 'Kiwi',\n",
       " 16: 'Lemon',\n",
       " 17: 'Litchi',\n",
       " 18: 'Longan',\n",
       " 19: 'Mandrian_Orange',\n",
       " 20: 'Mango',\n",
       " 21: 'Mangosteen',\n",
       " 22: 'Orange',\n",
       " 23: 'Pear',\n",
       " 24: 'Pineapple',\n",
       " 25: 'Pitaya',\n",
       " 26: 'Pomegranate',\n",
       " 27: 'Strawberry',\n",
       " 28: 'Tomato',\n",
       " 29: 'Watermelon'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8c747be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to local npy files\n",
    "np.save('idx_to_labels.npy', idx_to_labels)\n",
    "np.save('labels_to_idx.npy', train_dataset.class_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57372893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data loader for the training set\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4\n",
    "                         )\n",
    "\n",
    "# Data loader for the test set\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcbcc873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34e6bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f0cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "889af7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the attention mechanism layer\n",
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(in_channels, in_channels // reduction)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(in_channels // reduction, in_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.sigmoid(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf028348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Feature Pyramid Network (FPN)\n",
    "class FeaturePyramidNetwork(nn.Module):\n",
    "    def __init__(self, in_channels_list, out_channels):\n",
    "        super(FeaturePyramidNetwork, self).__init__()\n",
    "        self.lateral_convs = nn.ModuleList()\n",
    "        self.fpn_convs = nn.ModuleList()\n",
    "\n",
    "        for in_channels in in_channels_list:\n",
    "            self.lateral_convs.append(nn.Conv2d(in_channels, out_channels, kernel_size=1))\n",
    "            self.fpn_convs.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        laterals = [lat_conv(x[i]) for i, lat_conv in enumerate(self.lateral_convs)]\n",
    "        \n",
    "        for i in range(len(laterals) - 1, 0, -1):\n",
    "            laterals[i - 1] += nn.functional.interpolate(laterals[i], scale_factor=2, mode='nearest')\n",
    "\n",
    "        outs = [self.fpn_convs[i](laterals[i]) for i in range(len(laterals))]\n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b8d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained ResNet model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Add attention mechanism layers to the ResNet layers\n",
    "model.layer1 = nn.Sequential(model.layer1, AttentionModule(model.layer1[-1].bn3.num_features))\n",
    "model.layer2 = nn.Sequential(model.layer2, AttentionModule(model.layer2[-1].bn3.num_features))\n",
    "model.layer3 = nn.Sequential(model.layer3, AttentionModule(model.layer3[-1].bn3.num_features))\n",
    "model.layer4 = nn.Sequential(model.layer4, AttentionModule(model.layer4[-1].bn3.num_features))\n",
    "\n",
    "# Add the Feature Pyramid Network (FPN)\n",
    "in_channels_list = [model.layer1[-2][-1].bn3.num_features, \n",
    "                    model.layer2[-2][-1].bn3.num_features,\n",
    "                    model.layer3[-2][-1].bn3.num_features, \n",
    "                    model.layer4[-2][-1].bn3.num_features]\n",
    "fpn = FeaturePyramidNetwork(in_channels_list, 256)\n",
    "\n",
    "# Modify the fully connected layer to suit the fruit classification task\n",
    "num_classes = 30  \n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Number of training epochs\n",
    "EPOCHS = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0bbbef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(images, labels):\n",
    "    '''\n",
    "    Run training for one batch, return the training log for the current batch\n",
    "    '''\n",
    "    \n",
    "    # Get a batch of data and labels\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(images)  # Input the model, perform forward prediction\n",
    "    loss = criterion(outputs, labels)  # Compute the average cross-entropy loss value for each sample in the current batch\n",
    "    \n",
    "    # Optimize and update weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Get the label categories and predicted categories for the current batch\n",
    "    _, preds = torch.max(outputs, 1)  # Get the predicted categories for all images in the current batch\n",
    "    preds = preds.cpu().numpy()\n",
    "    loss = loss.detach().cpu().numpy()\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    \n",
    "    log_train = {}\n",
    "    log_train['epoch'] = epoch\n",
    "    log_train['batch'] = batch_idx\n",
    "    # Compute classification evaluation metrics\n",
    "    log_train['train_loss'] = loss\n",
    "    log_train['train_accuracy'] = accuracy_score(labels, preds)\n",
    "    # log_train['train_precision'] = precision_score(labels, preds, average='macro')\n",
    "    # log_train['train_recall'] = recall_score(labels, preds, average='macro')\n",
    "    # log_train['train_f1-score'] = f1_score(labels, preds, average='macro')\n",
    "    \n",
    "    return log_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4439cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_testset():\n",
    "    '''\n",
    "    Evaluate on the entire test set, return classification evaluation metrics log\n",
    "    '''\n",
    "\n",
    "    loss_list = []\n",
    "    labels_list = []\n",
    "    preds_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:  # Generate a batch of data and labels\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)  # Input the model, perform forward prediction\n",
    "\n",
    "            # Get the label categories and predicted categories for the entire test set\n",
    "            _, preds = torch.max(outputs, 1)  # Get the predicted categories for all images in the current batch\n",
    "            preds = preds.cpu().numpy()\n",
    "            loss = criterion(outputs, labels)  # From logits, compute the average cross-entropy loss value for each sample in the current batch\n",
    "            loss = loss.detach().cpu().numpy()\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "\n",
    "            loss_list.append(loss)\n",
    "            labels_list.extend(labels)\n",
    "            preds_list.extend(preds)\n",
    "        \n",
    "    log_test = {}\n",
    "    log_test['epoch'] = epoch\n",
    "    \n",
    "    # Compute classification evaluation metrics\n",
    "    log_test['test_loss'] = np.mean(loss_list)\n",
    "    log_test['test_accuracy'] = accuracy_score(labels_list, preds_list)\n",
    "    log_test['test_precision'] = precision_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_recall'] = recall_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_f1-score'] = f1_score(labels_list, preds_list, average='macro')\n",
    "    \n",
    "    return log_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09d5efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "batch_idx = 0\n",
    "best_test_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44dbc632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame\n",
    "df_train_log = pd.DataFrame()\n",
    "\n",
    "# Initialize log_train dictionary\n",
    "log_train = {'epoch': 0, 'batch': 0}\n",
    "\n",
    "# Get images and labels, this part of the code hasn't changed\n",
    "images, labels = next(iter(train_loader))\n",
    "log_train.update(train_one_batch(images, labels))\n",
    "\n",
    "# Convert log_train to DataFrame and use pd.concat to add to df_train_log\n",
    "log_train_df = pd.DataFrame([log_train])\n",
    "df_train_log = pd.concat([df_train_log, log_train_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "211f3d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.400956</td>\n",
       "      <td>0.03125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batch train_loss  train_accuracy\n",
       "0      0      0   3.400956         0.03125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5524963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame\n",
    "df_test_log = pd.DataFrame()\n",
    "\n",
    "# Initialize log_test dictionary\n",
    "log_test = {'epoch': 0}\n",
    "log_test.update(evaluate_testset())\n",
    "\n",
    "# Convert log_test to DataFrame and use pd.concat to add to df_test_log\n",
    "log_test_df = pd.DataFrame([log_test])\n",
    "df_test_log = pd.concat([df_test_log, log_test_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "107f7897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.406423</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>0.031711</td>\n",
       "      <td>0.009458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  test_loss  test_accuracy  test_precision  test_recall  test_f1-score\n",
       "0      0   3.406423       0.032468        0.015236     0.031711       0.009458"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0809d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "import time\n",
    "\n",
    "# wandb.init(project='fruit30', name=time.strftime('%m%d%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a28e2ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.882.pth\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.895.pth\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.900.pth\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:20<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.926.pth\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.931.pth\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.941.pth\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:20<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.944.pth\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.949.pth\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.950.pth\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:20<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.953.pth\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.955.pth\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.956.pth\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.959.pth\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.961.pth\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:19<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model checkpoint/best-0.963.pth\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    \n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    \n",
    "    ## Training phase\n",
    "    model.train()\n",
    "    batch_idx = 0\n",
    "    for images, labels in tqdm(train_loader):  # Get a batch of data and labels\n",
    "        batch_idx += 1\n",
    "        log_train = train_one_batch(images, labels)\n",
    "        # Use concat instead of append\n",
    "        df_train_log = pd.concat([df_train_log, pd.DataFrame([log_train])], ignore_index=True)\n",
    "        # wandb.log(log_train)\n",
    "        \n",
    "    lr_scheduler.step()\n",
    "\n",
    "    ## Testing phase\n",
    "    model.eval()\n",
    "    log_test = evaluate_testset()\n",
    "    # Use concat instead of append\n",
    "    df_test_log = pd.concat([df_test_log, pd.DataFrame([log_test])], ignore_index=True)\n",
    "    # wandb.log(log_test)\n",
    "    \n",
    "    # Save the latest best model file\n",
    "    if log_test['test_accuracy'] > best_test_accuracy: \n",
    "        # Delete the old best model file (if any)\n",
    "        old_best_checkpoint_path = 'checkpoint/best-{:.3f}.pth'.format(best_test_accuracy)\n",
    "        if os.path.exists(old_best_checkpoint_path):\n",
    "            os.remove(old_best_checkpoint_path)\n",
    "        # Save the new best model file\n",
    "        best_test_accuracy = log_test['test_accuracy']\n",
    "        new_best_checkpoint_path = 'checkpoint/best-{:.3f}.pth'.format(log_test['test_accuracy'])\n",
    "        torch.save(model, new_best_checkpoint_path)\n",
    "        print('Saved new best model', 'checkpoint/best-{:.3f}.pth'.format(best_test_accuracy))\n",
    "\n",
    "df_train_log.to_csv('training_log_train.csv', index=False)\n",
    "df_test_log.to_csv('training_log_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a27677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('checkpoint/best-{:.3f}.pth'.format(best_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae4310ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 30, 'test_loss': 0.13969468, 'test_accuracy': 0.9628942486085343, 'test_precision': 0.9646649507188062, 'test_recall': 0.961543996171616, 'test_f1-score': 0.962380868194248}\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_testset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8133b1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
